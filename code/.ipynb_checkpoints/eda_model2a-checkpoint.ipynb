{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UK Property Image Classification\n",
    "### EDA model 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data:\n",
    "Loading more images (150 each class, from 100) to build a second model\n",
    "Revised data set as of 13 Feb 2021 - 12 changes\n",
    "\n",
    "#### Model:\n",
    "Convoluted Neural Nets\n",
    "\n",
    "#### Initial model results:\n",
    "The model validation accuracy is 80%, compared to a base case of 50%. 200 images are used in the initial model training\n",
    "\n",
    "#### Training model with more images:\n",
    "Validation accuracy score is 78%, similar to that of a smaller set of images. Satisfactory results given that there is more confusion with more interior images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load folder into arrays and  then it returns that same array\n",
    "\n",
    "def load_files(path):\n",
    "    # Put files into lists and return them as one list of size 4\n",
    "    image_files = os.listdir(path)\n",
    "    image_files = [path + x for x in image_files]\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding images into numpy ndarray\n",
    "\n",
    "def load_array(image_files, min_size):\n",
    "    X = np.array([])\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            img = io.imread(file)\n",
    "            img_resized = resize(img, (min_size,min_size), anti_aliasing=True)\n",
    "            if X.shape[0] == 0:\n",
    "                X = np.array([img_resized])\n",
    "            else:\n",
    "                X = np.append(X, [img_resized], axis = 0)\n",
    "        \n",
    "        except:\n",
    "            print(\"image error: \", file)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training data - old buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of image_files = 251\n",
      "min_size = 400\n"
     ]
    }
   ],
   "source": [
    "# Photos of old or period buildings\n",
    "\n",
    "image_path = \"../images/old_samples/\"\n",
    "image_files = load_files(image_path)\n",
    "\n",
    "# second batch of old buildings - 150 images of interior\n",
    "image_path2 = \"../images/old_interior/\"\n",
    "image_files2 = load_files(image_path2)\n",
    "\n",
    "# concatenating 2 lists\n",
    "image_files = image_files + image_files2\n",
    "\n",
    "# set min_size = 400\n",
    "min_size = 400\n",
    "\n",
    "print(f\"number of image_files = {len(image_files)}\")\n",
    "print(f\"min_size = {min_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_file_info =                                         image_link\n",
      "0  ../images/old_samples/photo-14610337-AfvlL7.jpg\n",
      "1  ../images/old_samples/photo-14613473-oJlAGk.jpg\n",
      "2  ../images/old_samples/photo-14613600-uzDqQq.jpg\n",
      "3  ../images/old_samples/photo-14614603-V4bv1O.jpg\n",
      "4  ../images/old_samples/photo-14615502-8O2X6l.jpg\n"
     ]
    }
   ],
   "source": [
    "# look through the resolution of image files\n",
    "df_file_info = pd.DataFrame(image_files)\n",
    "df_file_info.columns = [\"image_link\"]\n",
    "print(f\"df_file_info = {df_file_info.head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "X_old = load_array(image_files, min_size)\n",
    "\n",
    "# y value is zero for old buildings\n",
    "y_old = np.zeros((len(image_files),1))\n",
    "\n",
    "print(f\"X_old shape = {X_old.shape}\")\n",
    "print(f\"y_old shape = {y_old.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_old = pd.DataFrame(y_old, columns=[\"label\"])\n",
    "df_y_old[\"image_link\"] = df_file_info[\"image_link\"]\n",
    "print(df_y_old.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Photos of modern buildings\n",
    "\n",
    "image_path = \"../images/modern_samples/\"\n",
    "image_files = load_files(image_path)\n",
    "\n",
    "# second batch of old buildings - 150 images of interior\n",
    "image_path2 = \"../images/modern_exterior/\"\n",
    "image_files2 = load_files(image_path2)\n",
    "\n",
    "# concatenating 2 lists\n",
    "image_files = image_files + image_files2\n",
    "\n",
    "# set min_size = 400\n",
    "min_size = 400\n",
    "\n",
    "print(f\"number of image_files = {len(image_files)}\")\n",
    "print(f\"min_size = {min_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look through the resolution of image files\n",
    "df_file_info = pd.DataFrame(image_files)\n",
    "df_file_info.columns = [\"image_link\"]\n",
    "print(f\"df_file_info = {df_file_info.head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modern = load_array(image_files, min_size)\n",
    "\n",
    "# y value is one for modern buildings\n",
    "y_modern = np.ones((len(image_files),1))\n",
    "\n",
    "print(f\"X_modern shape = {X_modern.shape}\")\n",
    "print(f\"y_modern shape = {y_modern.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_modern = pd.DataFrame(y_modern, columns=[\"label\"])\n",
    "df_y_modern[\"image_link\"] = df_file_info[\"image_link\"]\n",
    "print(df_y_modern.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(X_old, X_modern, axis = 0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.concat([df_y_old, df_y_modern])\n",
    "df_y.reset_index(drop=True, inplace=True)\n",
    "df_y[\"id\"] = df_y.index\n",
    "print(df_y.shape)\n",
    "df_y.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_y, stratify=df_y[\"label\"])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline accuracy - 50%\n",
    "y_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['id'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.flatten().reshape(-1,1)\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_flat = X_test.flatten().reshape(-1,1)\n",
    "X_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_ss = ss.fit_transform(X_train_flat).reshape(X_train.shape)\n",
    "X_test_ss = ss.transform(X_test_flat).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second run of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CNN.\n",
    "cnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer.\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 6,            # number of filters\n",
    "                     kernel_size = 3,        # height/width of filter\n",
    "                     activation='relu',      # activation function \n",
    "                     input_shape=(min_size,min_size,3))) # shape of input (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(MaxPooling2D(pool_size=(2,2))) # dimensions of region of pooling\n",
    "cnn_model.add(Conv2D(16,\n",
    "                     kernel_size=3,\n",
    "                     activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model.add(Flatten())\n",
    "# Add a densely-connected layer with 128 neurons.\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "# Add a final layer with 2 neurons.\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on training data\n",
    "history = cnn_model.fit(X_train_ss,\n",
    "                        y_train['label'],\n",
    "                        batch_size=64,\n",
    "                        validation_data=(X_test_ss, y_test['label']),\n",
    "                        epochs=30,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_loss, label='Training loss', color='navy')\n",
    "plt.plot(test_loss, label='Testing loss', color='skyblue')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List out the images of misclassification - test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn_model.predict(X_test_ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['pred'] = y_pred.round()\n",
    "y_test['prob'] = y_pred.round(3)\n",
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of photos misclassified in y_test\n",
    "y_test_misclassified = y_test[[\"image_link\", \"label\", \"pred\", \"prob\"]][y_test[\"label\"] != y_test[\"pred\"]]\n",
    "\n",
    "print(f\"total number in y_test: {y_test.shape[0]}\")\n",
    "print(f\"misclassified in y_test: {y_test_misclassified.shape[0]}\")\n",
    "y_test_misclassified.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 20 photos misclassified in y_test\n",
    "display_no = min(20, y_test_misclassified.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(ceil(display_no/2), 2, figsize=(8,32))\n",
    "j=0\n",
    "for i in y_test_misclassified.index[:display_no]:\n",
    "    row = j//2\n",
    "    col = j%2\n",
    "    image_link = y_test_misclassified.loc[i, \"image_link\"]\n",
    "    ax[row][col].imshow(io.imread(image_link))\n",
    "    ax[row][col].set_title(\"label:\" + str(y_test_misclassified.loc[i, \"label\"]) + \", pred:\" + str(y_test_misclassified.loc[i, \"pred\"]) + \"prob:\"  + str(y_test_misclassified.loc[i, \"prob\"]))\n",
    "    ax[row][col].axis('off')\n",
    "    j += 1\n",
    "\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"model2a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler\n",
    "pickle.dump(ss, open('../models/' + model_tag + '/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model = cnn_model\n",
    "\n",
    "path = '../models/' + model_tag + '/'\n",
    "model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
