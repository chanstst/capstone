{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukvRYqjGdwgu"
      },
      "source": [
        "# Problem statement:\r\n",
        "- Classifying if the image belongs to a period or modern property in UK\r\n",
        "\r\n",
        "# Modelling using VGG16\r\n",
        "- Total number of images: 491\r\n",
        "- Images of period buildings: 241\r\n",
        "- Images of modern buildings: 250\r\n",
        "\r\n",
        "Model parameters:\r\n",
        "- Dense layer: 128 neurons\r\n",
        "- Dropout: 0.5\r\n",
        "- Early Stopping: patience=5\r\n",
        "\r\n",
        "Model results:\r\n",
        "- Accuracy: 82%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrIUlAv2pvYQ"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT-bu_OlqNhb"
      },
      "source": [
        "! pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPEgfaN6rtXP"
      },
      "source": [
        "!pip install pandas\r\n",
        "!pip install numpy\r\n",
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJuQ2pgxtmS3"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieRbE-ljsYeu"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoDnX_9-tPpe"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFTwKeI4s4Vm"
      },
      "source": [
        "\r\n",
        "from math import ceil\r\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG-NrLyCtAGo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0RDoV7ctKZ3"
      },
      "source": [
        "from skimage import io\r\n",
        "from skimage import color\r\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIB6N9BHtVe6"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWn6xdX9rcBy"
      },
      "source": [
        "# function to load folder into arrays and  then it returns that same array\r\n",
        "\r\n",
        "def load_files(path):\r\n",
        "    # Put files into lists and return them as one list of size 4\r\n",
        "    image_files = os.listdir(path)\r\n",
        "    image_files = [path + x for x in image_files]\r\n",
        "    return image_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUVJEfSFuG-J"
      },
      "source": [
        "# feeding images into numpy ndarray\r\n",
        "\r\n",
        "def load_array(image_files, min_size):\r\n",
        "    X = np.array([])\r\n",
        "    for file in image_files:\r\n",
        "        try:\r\n",
        "            img = io.imread(file)\r\n",
        "            img_resized = resize(img, (min_size,min_size), anti_aliasing=True)\r\n",
        "            if X.shape[0] == 0:\r\n",
        "                X = np.array([img_resized])\r\n",
        "            else:\r\n",
        "                X = np.append(X, [img_resized], axis = 0)\r\n",
        "        except:\r\n",
        "            print(\"image error: \", file)\r\n",
        "    return X\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGbWP4TBqr9c"
      },
      "source": [
        "# For reproducibility\r\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kz1PZn2qbXr"
      },
      "source": [
        "# Colab path\r\n",
        "path = '/content/drive/MyDrive/Capstone'\r\n",
        "image_path = path + '/images/old_samples/'\r\n",
        "image_path2 = path + \"/images/old_interior/\"\r\n",
        "\r\n",
        "# Photos of old or period buildings\r\n",
        "image_files = load_files(image_path)\r\n",
        "\r\n",
        "# second batch of old buildings - 150 images of interior\r\n",
        "image_files2 = load_files(image_path2)\r\n",
        "\r\n",
        "# concatenating 2 lists\r\n",
        "image_files = image_files + image_files2\r\n",
        "\r\n",
        "# set min_size = 400\r\n",
        "min_size = 400\r\n",
        "\r\n",
        "print(f\"number of image_files = {len(image_files)}\")\r\n",
        "print(f\"min_size = {min_size}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyGar_ZvuLLv"
      },
      "source": [
        "# record the path of image files\r\n",
        "df_file_info = pd.DataFrame(image_files)\r\n",
        "df_file_info.columns = [\"image_link\"]\r\n",
        "print(f\"df_file_info = {df_file_info.head(5)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvKmRAjwuYic"
      },
      "source": [
        "X_old = load_array(image_files, min_size)\r\n",
        "\r\n",
        "# y value is zero for old buildings\r\n",
        "y_old = np.zeros((len(image_files),1))\r\n",
        "\r\n",
        "print(f\"X_old shape = {X_old.shape}\")\r\n",
        "print(f\"y_old shape = {y_old.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcY2Z-1ExalL"
      },
      "source": [
        "df_y_old = pd.DataFrame(y_old, columns=[\"label\"])\r\n",
        "df_y_old[\"image_link\"] = df_file_info[\"image_link\"]\r\n",
        "print(df_y_old.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbIKpNEHvnH7"
      },
      "source": [
        "# Photos of modern buildings\r\n",
        "\r\n",
        "# Colab path\r\n",
        "path = '/content/drive/MyDrive/Capstone'\r\n",
        "image_path = path + '/images/modern_samples/'\r\n",
        "image_path2 = path + \"/images/modern_exterior/\"\r\n",
        "\r\n",
        "image_files = load_files(image_path)\r\n",
        "\r\n",
        "# second batch of old buildings - 150 images of interior\r\n",
        "image_files2 = load_files(image_path2)\r\n",
        "\r\n",
        "# concatenating 2 lists\r\n",
        "image_files = image_files + image_files2\r\n",
        "\r\n",
        "# set min_size = 400\r\n",
        "min_size = 400\r\n",
        "\r\n",
        "print(f\"number of image_files = {len(image_files)}\")\r\n",
        "print(f\"min_size = {min_size}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u20DfrhNwGMU"
      },
      "source": [
        "# record the path of image files\r\n",
        "df_file_info = pd.DataFrame(image_files)\r\n",
        "df_file_info.columns = [\"image_link\"]\r\n",
        "print(f\"df_file_info = {df_file_info.head(5)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI6VIaDvwUmj"
      },
      "source": [
        "X_modern = load_array(image_files, min_size)\r\n",
        "\r\n",
        "# y value is one for modern buildings\r\n",
        "y_modern = np.ones((len(image_files),1))\r\n",
        "\r\n",
        "print(f\"X_modern shape = {X_modern.shape}\")\r\n",
        "print(f\"y_modern shape = {y_modern.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ZM8Hc2xJDM"
      },
      "source": [
        "df_y_modern = pd.DataFrame(y_modern, columns=[\"label\"])\r\n",
        "df_y_modern[\"image_link\"] = df_file_info[\"image_link\"]\r\n",
        "print(df_y_modern.shape)\r\n",
        "X = np.append(X_old, X_modern, axis = 0)\r\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwYDN6RExQ2Y"
      },
      "source": [
        "df_y = pd.concat([df_y_old, df_y_modern])\r\n",
        "df_y.reset_index(drop=True, inplace=True)\r\n",
        "df_y[\"id\"] = df_y.index\r\n",
        "print(df_y.shape)\r\n",
        "df_y.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MDFcI7cx6f5"
      },
      "source": [
        "# train test split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df_y, stratify=df_y[\"label\"])\r\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBIyy4iWyQyg"
      },
      "source": [
        "# Baseline accuracy - 50%\r\n",
        "y_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Robrxq7ySEs"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu1oAlSxyVQT"
      },
      "source": [
        "y_test['id'][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qstmL23yYjv"
      },
      "source": [
        "plt.imshow(X_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVhO2zKVygGk"
      },
      "source": [
        "# Standard Scaler - skipped\r\n",
        "X_train_ss = X_train\r\n",
        "X_test_ss = X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHPee1jPtuzr"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "IMG_SIZE = (400, 400)\r\n",
        "\r\n",
        "# Create the base model from the pre-trained model VGG16\r\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\r\n",
        "input_model = VGG16(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzyKifrYt2K8"
      },
      "source": [
        "input_model.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ5dUfhit8x7"
      },
      "source": [
        "# add new classifier layers\r\n",
        "# add dropout = 0.5\r\n",
        "flat1 = Flatten()(input_model.layers[-1].output)\r\n",
        "class1 = Dense(128, activation='relu')(flat1)\r\n",
        "class2 = Dropout(0.5)(class1)\r\n",
        "output = Dense(1, activation='sigmoid')(class2)\r\n",
        "# define new model\r\n",
        "model = Model(inputs=input_model.inputs, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vILyizWht_3Y"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h64Rj1HpXQlM"
      },
      "source": [
        "# early stopper\r\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoFD16Rvyn98"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\r\n",
        "                  optimizer='adam',\r\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs9gooJcyvlc",
        "outputId": "d747d927-d4e6-42d4-e0d1-360a3f3aa455"
      },
      "source": [
        "# Fit model on training data\r\n",
        "history = model.fit(X_train_ss,\r\n",
        "                        y_train['label'],\r\n",
        "                        batch_size=32,\r\n",
        "                        validation_data=(X_test_ss, y_test['label']),\r\n",
        "                        epochs=30,\r\n",
        "                        verbose=1,\r\n",
        "                        callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 723s 61s/step - loss: 3.7677 - accuracy: 0.5273 - val_loss: 0.6233 - val_accuracy: 0.5447\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 716s 61s/step - loss: 0.6379 - accuracy: 0.6123 - val_loss: 0.5407 - val_accuracy: 0.8049\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 703s 60s/step - loss: 0.4922 - accuracy: 0.7973 - val_loss: 0.4604 - val_accuracy: 0.8049\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 706s 60s/step - loss: 0.4284 - accuracy: 0.7726 - val_loss: 0.4439 - val_accuracy: 0.8130\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 706s 60s/step - loss: 0.4053 - accuracy: 0.8433 - val_loss: 0.4137 - val_accuracy: 0.8130\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 707s 60s/step - loss: 0.3575 - accuracy: 0.8533 - val_loss: 0.4403 - val_accuracy: 0.8211\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 709s 60s/step - loss: 0.3329 - accuracy: 0.8831 - val_loss: 0.3801 - val_accuracy: 0.8293\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 704s 60s/step - loss: 0.3062 - accuracy: 0.8444 - val_loss: 0.3899 - val_accuracy: 0.8049\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 708s 60s/step - loss: 0.2813 - accuracy: 0.8626 - val_loss: 0.3801 - val_accuracy: 0.8293\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 705s 60s/step - loss: 0.2074 - accuracy: 0.9058 - val_loss: 0.3969 - val_accuracy: 0.8211\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 706s 60s/step - loss: 0.1707 - accuracy: 0.9297 - val_loss: 0.3788 - val_accuracy: 0.8130\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 710s 60s/step - loss: 0.1736 - accuracy: 0.9221 - val_loss: 0.3817 - val_accuracy: 0.8049\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 709s 60s/step - loss: 0.1235 - accuracy: 0.9568 - val_loss: 0.3967 - val_accuracy: 0.8293\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 707s 60s/step - loss: 0.1088 - accuracy: 0.9636 - val_loss: 0.3727 - val_accuracy: 0.8455\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 706s 60s/step - loss: 0.1127 - accuracy: 0.9514 - val_loss: 0.4090 - val_accuracy: 0.8618\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 709s 60s/step - loss: 0.1051 - accuracy: 0.9638 - val_loss: 0.3919 - val_accuracy: 0.8130\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 709s 60s/step - loss: 0.0896 - accuracy: 0.9609 - val_loss: 0.3772 - val_accuracy: 0.8130\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9391 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9_H1HeWNHSg"
      },
      "source": [
        "model_tag = \"vgg16_a\"\r\n",
        "\r\n",
        "model_path = path + '/models/' + model_tag + '/'\r\n",
        "model.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}